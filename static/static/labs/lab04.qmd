---
title: "Lab 04: Seoul Bicycle Share"
author: "STA 101"
subtitle: "Due Thursday October 6 at 11:59pm"
format: html
css: "labs2.css"
---

By the end of this lab you will

- build interaction effects models
- select between competing models
- build a logistic regression model and assess its performance
- make predictions using your model

## Getting started

\ 1. Download the lab template by pasting the code below in your **console**:

```
download.file("https://sta101-fa22.netlify.app/static/labs/lab04_template.qmd",
              destfile = "lab04.qmd")
```

\ 2. Under the "Files" tab on the right hand side, click on `lab04.qmd` to open the lab template.


\ 3. Complete the exercises below using the space provided.

## Warm up

Be sure to update the YAML at the top of the document to include your name and the date.

### Packages

```{r load-packages, warning=F, message=F}
library(tidyverse)
library(tidymodels)
```

### Data

Load the data:

```{r load-data, warning=F, message=F}
Seoul_Bikes = read_csv("https://sta101-fa22.netlify.app/static/appex/data/Seoul_Bikes.csv") 
Seoul_Calendar = read_csv("https://sta101-fa22.netlify.app/static/appex/data/Seoul_Calendar.csv")
```

Today's data set was originally analyzed in two studies[^1] of predicting bike-rental usage in Seoul, South Korea. For this lab, the data was sourced from [UCI Machine Learning Repository](https://archive.ics.uci.edu).

[^1]: Sathishkumar V E, Jangwoo Park, and Yongyun Cho. 'Using data mining techniques for bike sharing demand prediction in metropolitan city.' Computer Communications, Vol.153, pp.353-366, March, 2020; Sathishkumar V E and Yongyun Cho. 'A rule-based model for Seoul Bike sharing demand prediction using weather data' European Journal of Remote Sensing, pp. 1-18, Feb, 2020

Code book:

- `Date`: the date
- `rented_bikes`: total number of bikes rented on a given day
- `temp_c`: mean daily temperature (Celcius)
-  `humidity_pct`: mean daily humidity
- `wind_speed`: mean daily windspeed
- `snowfall_cm`: mean daily snowfall (in cm)
- `season`: the season
- `holiday`: whether or not the day is a holiday


## Exercises

1. Use an appropriate `join` to combine the two data sets into one data set called `bikes`. `bikes` should have 365 observations and 8 variables.

```{r join, echo=F, message =F, warning = F}
bikes = left_join(Seoul_Bikes, Seoul_Calendar)
```


2. Does the total number of `rented_bikes` vary by `season`? Create a meaningful visual to back-up your claim. Comment on your plot. Be sure to label axes and give your plot a title.

3. Seoul Bikesharing Co. wants to predict how many bikes they will rent on a given day using the data in `bikes`. They are particularly interested in how important the weather is in determining whether or not people will rent their bikes. Seoul Bikesharing Co. asks you and your friend to develop the best linear model you can with temperature, humidity, wind speed and snowfall as predictors.

To begin, your friend builds a **main effects** model using **forward selection**. 

- In your own words, what does this mean?

Your friend's code to build a main effects model using forward selection is given below.

- Find the AIC for each of your friend's fitted models.

- In **one** of the **steps** below your friend adds the wrong predictor. Identify your friend's mistake and fix it.

- Which model (of the forward selection procedure *after* your correct your friend's mistake) performs the best?

#### Step 1 of forward selection

```{r step-1}
bike_fit_1_1 = bike_fit = linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ temp_c, data = bikes)

bike_fit_1_2 = bike_fit = linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ humidity_pct, data = bikes)

bike_fit_1_3 = bike_fit = linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ wind_speed, data = bikes)

bike_fit_1_4 = bike_fit = linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ snowfall_cm, data = bikes)
```


#### Step 2 of forward selection 

```{r step-2}
bike_fit_2_1 = bike_fit = linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ temp_c + snowfall_cm, data = bikes)

bike_fit_2_2 = bike_fit = linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ temp_c + humidity_pct, data = bikes)

bike_fit_2_3 = bike_fit = linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ temp_c + wind_speed, data = bikes)
```


#### Step 3 of forward selection

```{r step-3}
bike_fit_3_1 = bike_fit = 
  linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ temp_c + wind_speed + snowfall_cm, data = bikes)

bike_fit_3_2 = bike_fit = linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ temp_c + wind_speed + humidity_pct, data = bikes)
```

#### Step 4 of forward selection 

```{r}
bike_fit_full = bike_fit = linear_reg() %>%
  set_engine('lm') %>%
  fit(rented_bikes ~ temp_c + humidity_pct + wind_speed + snowfall_cm, data = bikes)
```


4. In addition to your friend's work above, you decide to run **backwards elimination** to construct the best model. You proceed in a similar manner as in the code above and at each step choose variables to eliminate based on AIC. Once you are complete, specify which model has the best performance. Is it the same model as the one chosen by forward stepwise selection? Will it always be the case that the models chosen through forward selection and backwards elimination coincide? Why or why not? 

5. Some days the weather predicts high sales yet many fewer bikes are rented. You suspect bikes are mainly rented  to commute to work and that there are fewer bikes rented on Holidays, unless the weather is very nice. You create the plot below to investigate.

```{r, echo = F, message = F, warning = F}
bikes %>%
  ggplot(aes(x = temp_c, y = rented_bikes, color = holiday)) +
  geom_point(alpha = 0.5) +
  theme_bw() +
  labs(x = "Temperature", y = "Rented No. Bikes", color = "Holiday?",
       title = "Rented Bicycles in Seoul") +
  scale_color_manual(values = c("red", "#00539B")) +
  geom_smooth(method = 'lm')
```

The lines drawn in the plot above represent a regression model. Is this an **main** effects or an **interaction** effects model? How can you tell?

- Write out the full linear model, labeling $y$ and $x$ and then fit the model in `R` and print your output.

- Next, write out the fitted model equation as two equations, one for Holidays and one for Non-holidays. Interpret the slopes in each of the two equations.

- Does this model perform better or worse then your best model from the previous exercise?

6. Seoul Bikesharing Co. say they need to rent 7000 bikes in a day to count the day as a "financial success". Create a new column in the data set titled `success` that takes the value `1` if the day is successful and `0` if the day is unsuccessful. Save your data set with the new column as `bikes2`.

7. As a stakeholder in Seoul Bikesharing Co. you want to be able to tell how many financially successful days the company has, even if they stop publically publishing how many bikes they rent each day. To do this, you will build a predictive model to determine whether or not a day was successful.

- To begin, use the code below to create a `train` and `test` data set. Be sure to use the same seed as well.

```{r, eval = F}
set.seed(7)
sampleIndices = sample.int(n = nrow(bikes2), size = 180, replace = F)
train = bikes2[sampleIndices, ]
test  = bikes2[-sampleIndices, ] %>%
  slice_sample(n = 180)
```

- Next, fit a main effects logistic regression model that predicts prob(`success`) from `temp_c`, `humidity_pct` and `holiday` using the `train` data set. Print your model `tidy`.

8. Edit the code chunk below, specifically renaming `model_fit` and `test_data` where appropriate. Un-comment and run to find the predicted probabilities of financially successful days in the `test` data frame.

```{r test-predictions}
# prediction = predict(model_fit, test_data, type = "prob")

# test_result = test_data %>%
#   mutate(predicted_prob_success = prediction$.pred_1)
```

Next, building on your `test_result` data frame, create a new column that classifies a day as successful if the predicted probability is above 50%. Repeat with a decision boundary of 75% and 90%. 

How many false positives do you have in each case? False negatives? If you were to use your model as a marker of how well the company is doing to decide whether to hold or sell your shares which decision boundary would you prefer and why?

Note: your narrative should read, e.g.: "With a decision boundary of 50%, my model yields X false positives and Y false negatives. With a decision boundary of 75%..." etc.


## Formatting

**Reminder**: For all assignments in this course there is a "formatting" component to the grade. To receive full points for "formatting", you must:

\ 1. Have your name at the top of the rendered document

\ 2. Pipes `%>%` and ggplot layers `+` should be followed by a newline (see formatting above)

\ 3. Your code should be under the 80 character code limit. (You shouldn't have to scroll to see all your code on the rendered document).

\ 4. All exercises and corresponding pages should be linked on gradescope.

These necessary "tidyverse" style choices are good general practice and will help make your code more legible. For a more extensive list of recommended guidelines, [click here](https://style.tidyverse.org/).

## Submitting to gradescope

Once you are fully satisfied with your lab, render to .pdf to create a .pdf document. You may notice that the formatting/theme of the report has changed – this is expected. Remember – you must turn in a .pdf file to the Gradescope page before the submission deadline for credit. To submit your assignment: 

- Go to [http://www.gradescope.com](http://www.gradescope.com) and click Log in in the top right corner. - Click `School Credentials`, `Duke NetID` and log in using your NetID credentials. 

- Click on your STA 101 course. 

- Click on the assignment, and you'll be prompted to submit it. 

- Mark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”). Select the first page of your .pdf submission to be associated with the "Formatting" section.

## Grading

Total: 50 pts.

    Exercise 1: 2pts

    Exercise 2: 5pts

    Exercise 3: 7pts

    Exercise 4: 7pts

    Exercise 5: 9pts
    
    Exercise 6: 3pts
    
    Exercise 7: 6pts
    
    Exercise 8: 7pts
    
    Workflow and formatting:  4pts
    